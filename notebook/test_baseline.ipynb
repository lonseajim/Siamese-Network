{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import baseline as baseline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "820436613d6d9530",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_list = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for cv in cv_list:\n",
    "    support_df = pd.read_csv('data/few_P300_cv{}_100.csv'.format(cv))\n",
    "    support_file_list = support_df['data_file'].to_numpy()\n",
    "    support_label_list = support_df['label'].to_numpy()\n",
    "    # split dataset\n",
    "    support_data_df = None\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in skf.split(support_file_list, support_label_list):\n",
    "        support_data_df = support_df.iloc[test_index]\n",
    "        # break\n",
    "    print('support data len: {}'.format(len(support_data_df)))\n",
    "\n",
    "    query_data_df = pd.read_csv('data/test_R300_cv{}_3900.csv'.format(cv))\n",
    "    print('query data len: {}'.format(len(query_data_df)))\n",
    "\n",
    "    correct_count = 0\n",
    "    for q_i, query_data in query_data_df.iterrows():\n",
    "        q_data = np.loadtxt(query_data['data_file'], delimiter='\\t', dtype=float).T\n",
    "        q_data_y = q_data[1]\n",
    "\n",
    "        true_label = int(query_data['label'])\n",
    "\n",
    "        sim_list, support_label_list = [], []\n",
    "        for s_i, support_data in support_data_df.iterrows():\n",
    "            s_data = np.loadtxt(support_data['data_file'], delimiter='\\t', dtype=float).T\n",
    "            s_data_y = s_data[1]\n",
    "\n",
    "            support_label = int(support_data['label'])\n",
    "            support_label_list.append(support_label)\n",
    "\n",
    "            # output = baseline.dist_Euclidean(q_data_y, s_data_y)\n",
    "            output = baseline.dist_Manhattan(q_data_y, s_data_y)\n",
    "            # output = baseline.dis_cosine(q_data_y, s_data_y)\n",
    "            sim_list.append(output)\n",
    "\n",
    "        pred_label_index = sim_list.index(min(sim_list))\n",
    "        # print(sim_list)\n",
    "\n",
    "        if true_label == support_label_list[pred_label_index]:\n",
    "            correct_count += 1\n",
    "        # print(true_label, support_label_list[pred_label_index])\n",
    "\n",
    "    print('cv: {}, acc: {:.8f}'.format(cv, correct_count / len(query_data_df)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cda9678ef4dc503e",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
